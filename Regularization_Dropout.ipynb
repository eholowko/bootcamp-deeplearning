{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import Sequential\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K # własna funkcja w kerasie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2,l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jak radzić sobie z przeuczaniem modelu? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na początek - zbudujmy model, który się przeuczy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_digits, y_digits = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "X_digits_train_raw, X_digits_test_raw, y_digits_train, y_digits_test = train_test_split(X_digits, y_digits, test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_digits_train = scaler.fit_transform(X_digits_train_raw)\n",
    "X_digits_test = scaler.transform(X_digits_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_digits_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60,input_dim=X_digits_train.shape[1],activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 1, 8, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_digits_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(y_digits_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.1142 - acc: 0.2840\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.3275 - acc: 0.6626\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.8915 - acc: 0.8018\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.6393 - acc: 0.8920\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.4789 - acc: 0.9109\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.3793 - acc: 0.9321\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.3099 - acc: 0.9510\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.2607 - acc: 0.9566\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.2240 - acc: 0.9633\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.1953 - acc: 0.9677\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.1735 - acc: 0.9744\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.1536 - acc: 0.9744\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.1377 - acc: 0.9788\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.1239 - acc: 0.9855\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.1135 - acc: 0.9855\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.1025 - acc: 0.9866\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0939 - acc: 0.9878\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0862 - acc: 0.9900\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0793 - acc: 0.9900\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0732 - acc: 0.9911\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0676 - acc: 0.9911\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0625 - acc: 0.9922\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0579 - acc: 0.9933\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0537 - acc: 0.9933\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0503 - acc: 0.9933\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0466 - acc: 0.9933\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0434 - acc: 0.9955\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0406 - acc: 0.9967\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0381 - acc: 0.9955\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0357 - acc: 0.9978\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0347 - acc: 0.9978\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0331 - acc: 0.9989\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0308 - acc: 0.9989\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0281 - acc: 0.9989\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0234 - acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0117 - acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0024 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6317c1dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_digits_train,to_categorical(y_digits_train),epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 0s 152us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0023497095216689985, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_train,to_categorical(y_digits_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 46us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10815979533303566, 0.9755283648498332]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_test,to_categorical(y_digits_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularyzacja "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak w modelach liniowych, tak i tutaj możemy nałożyć kary na wielkość naszych wag. Idea jest taka sama jak wcześniej - optymalizujemy sumę funkcji straty oraz kary regularyzującej. Do wyboru mamy regularyzację `l1`, lub `l2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pierwsza wspórzędna to suma logloss i regularyzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1 = 0.003\n",
    "lambda_2 = 0.001\n",
    "model = Sequential()\n",
    "model.add(Dense(60,input_dim=X_digits_train.shape[1],activation='relu',kernel_regularizer=l2(lambda_1)))\n",
    "model.add(Dense(10,activation='softmax',kernel_regularizer=l2(lambda_2)))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['categorical_crossentropy','accuracy'],optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "898/898 [==============================] - 1s 680us/step - loss: 2.3742 - categorical_crossentropy: 2.1779 - acc: 0.2060\n",
      "Epoch 2/100\n",
      "898/898 [==============================] - 0s 75us/step - loss: 1.5861 - categorical_crossentropy: 1.3945 - acc: 0.6269\n",
      "Epoch 3/100\n",
      "898/898 [==============================] - 0s 78us/step - loss: 1.1266 - categorical_crossentropy: 0.9343 - acc: 0.8085\n",
      "Epoch 4/100\n",
      "898/898 [==============================] - 0s 116us/step - loss: 0.8664 - categorical_crossentropy: 0.6723 - acc: 0.8742\n",
      "Epoch 5/100\n",
      "898/898 [==============================] - 0s 96us/step - loss: 0.7063 - categorical_crossentropy: 0.5104 - acc: 0.9109\n",
      "Epoch 6/100\n",
      "898/898 [==============================] - 0s 93us/step - loss: 0.5997 - categorical_crossentropy: 0.4026 - acc: 0.9265\n",
      "Epoch 7/100\n",
      "898/898 [==============================] - 0s 91us/step - loss: 0.5276 - categorical_crossentropy: 0.3298 - acc: 0.9388\n",
      "Epoch 8/100\n",
      "898/898 [==============================] - 0s 86us/step - loss: 0.4755 - categorical_crossentropy: 0.2773 - acc: 0.9488\n",
      "Epoch 9/100\n",
      "898/898 [==============================] - 0s 91us/step - loss: 0.4362 - categorical_crossentropy: 0.2382 - acc: 0.9577\n",
      "Epoch 10/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.4051 - categorical_crossentropy: 0.2075 - acc: 0.9655\n",
      "Epoch 11/100\n",
      "898/898 [==============================] - 0s 114us/step - loss: 0.3802 - categorical_crossentropy: 0.1834 - acc: 0.9722\n",
      "Epoch 12/100\n",
      "898/898 [==============================] - 0s 84us/step - loss: 0.3612 - categorical_crossentropy: 0.1655 - acc: 0.9722\n",
      "Epoch 13/100\n",
      "898/898 [==============================] - 0s 103us/step - loss: 0.3458 - categorical_crossentropy: 0.1513 - acc: 0.9800\n",
      "Epoch 14/100\n",
      "898/898 [==============================] - 0s 81us/step - loss: 0.3292 - categorical_crossentropy: 0.1361 - acc: 0.9833\n",
      "Epoch 15/100\n",
      "898/898 [==============================] - 0s 103us/step - loss: 0.3164 - categorical_crossentropy: 0.1250 - acc: 0.9866\n",
      "Epoch 16/100\n",
      "898/898 [==============================] - 0s 96us/step - loss: 0.3054 - categorical_crossentropy: 0.1156 - acc: 0.9889\n",
      "Epoch 17/100\n",
      "898/898 [==============================] - 0s 100us/step - loss: 0.2957 - categorical_crossentropy: 0.1078 - acc: 0.9889\n",
      "Epoch 18/100\n",
      "898/898 [==============================] - 0s 76us/step - loss: 0.2861 - categorical_crossentropy: 0.1000 - acc: 0.9900\n",
      "Epoch 19/100\n",
      "898/898 [==============================] - 0s 80us/step - loss: 0.2782 - categorical_crossentropy: 0.0940 - acc: 0.9900\n",
      "Epoch 20/100\n",
      "898/898 [==============================] - 0s 80us/step - loss: 0.2702 - categorical_crossentropy: 0.0880 - acc: 0.9933\n",
      "Epoch 21/100\n",
      "898/898 [==============================] - 0s 86us/step - loss: 0.2629 - categorical_crossentropy: 0.0828 - acc: 0.9933\n",
      "Epoch 22/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.2569 - categorical_crossentropy: 0.0790 - acc: 0.9944\n",
      "Epoch 23/100\n",
      "898/898 [==============================] - 0s 84us/step - loss: 0.2499 - categorical_crossentropy: 0.0744 - acc: 0.9955\n",
      "Epoch 24/100\n",
      "898/898 [==============================] - 0s 109us/step - loss: 0.2447 - categorical_crossentropy: 0.0713 - acc: 0.9955\n",
      "Epoch 25/100\n",
      "898/898 [==============================] - 0s 81us/step - loss: 0.2395 - categorical_crossentropy: 0.0683 - acc: 0.9955\n",
      "Epoch 26/100\n",
      "898/898 [==============================] - 0s 65us/step - loss: 0.2352 - categorical_crossentropy: 0.0661 - acc: 0.9955\n",
      "Epoch 27/100\n",
      "898/898 [==============================] - 0s 89us/step - loss: 0.2303 - categorical_crossentropy: 0.0631 - acc: 0.9955\n",
      "Epoch 28/100\n",
      "898/898 [==============================] - 0s 77us/step - loss: 0.2250 - categorical_crossentropy: 0.0600 - acc: 0.9955\n",
      "Epoch 29/100\n",
      "898/898 [==============================] - 0s 79us/step - loss: 0.2205 - categorical_crossentropy: 0.0576 - acc: 0.9967\n",
      "Epoch 30/100\n",
      "898/898 [==============================] - 0s 90us/step - loss: 0.2164 - categorical_crossentropy: 0.0557 - acc: 0.9967\n",
      "Epoch 31/100\n",
      "898/898 [==============================] - 0s 104us/step - loss: 0.2128 - categorical_crossentropy: 0.0542 - acc: 0.9978\n",
      "Epoch 32/100\n",
      "898/898 [==============================] - 0s 73us/step - loss: 0.2090 - categorical_crossentropy: 0.0526 - acc: 0.9967\n",
      "Epoch 33/100\n",
      "898/898 [==============================] - 0s 88us/step - loss: 0.2057 - categorical_crossentropy: 0.0514 - acc: 0.9967\n",
      "Epoch 34/100\n",
      "898/898 [==============================] - 0s 81us/step - loss: 0.2027 - categorical_crossentropy: 0.0504 - acc: 0.9978\n",
      "Epoch 35/100\n",
      "898/898 [==============================] - 0s 94us/step - loss: 0.1996 - categorical_crossentropy: 0.0493 - acc: 0.9978\n",
      "Epoch 36/100\n",
      "898/898 [==============================] - 0s 66us/step - loss: 0.1956 - categorical_crossentropy: 0.0473 - acc: 0.9978\n",
      "Epoch 37/100\n",
      "898/898 [==============================] - 0s 109us/step - loss: 0.1925 - categorical_crossentropy: 0.0462 - acc: 0.9978\n",
      "Epoch 38/100\n",
      "898/898 [==============================] - 0s 66us/step - loss: 0.1898 - categorical_crossentropy: 0.0456 - acc: 0.9967\n",
      "Epoch 39/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.1869 - categorical_crossentropy: 0.0447 - acc: 0.9978\n",
      "Epoch 40/100\n",
      "898/898 [==============================] - 0s 88us/step - loss: 0.1843 - categorical_crossentropy: 0.0440 - acc: 0.9978\n",
      "Epoch 41/100\n",
      "898/898 [==============================] - 0s 92us/step - loss: 0.1817 - categorical_crossentropy: 0.0433 - acc: 0.9978\n",
      "Epoch 42/100\n",
      "898/898 [==============================] - 0s 92us/step - loss: 0.1797 - categorical_crossentropy: 0.0430 - acc: 0.9967\n",
      "Epoch 43/100\n",
      "898/898 [==============================] - 0s 73us/step - loss: 0.1770 - categorical_crossentropy: 0.0422 - acc: 0.9978\n",
      "Epoch 44/100\n",
      "898/898 [==============================] - 0s 78us/step - loss: 0.1744 - categorical_crossentropy: 0.0413 - acc: 0.9978\n",
      "Epoch 45/100\n",
      "898/898 [==============================] - 0s 84us/step - loss: 0.1724 - categorical_crossentropy: 0.0410 - acc: 0.9978\n",
      "Epoch 46/100\n",
      "898/898 [==============================] - 0s 100us/step - loss: 0.1702 - categorical_crossentropy: 0.0405 - acc: 0.9989\n",
      "Epoch 47/100\n",
      "898/898 [==============================] - 0s 66us/step - loss: 0.1684 - categorical_crossentropy: 0.0402 - acc: 0.9978\n",
      "Epoch 48/100\n",
      "898/898 [==============================] - 0s 102us/step - loss: 0.1661 - categorical_crossentropy: 0.0395 - acc: 0.9989\n",
      "Epoch 49/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.1643 - categorical_crossentropy: 0.0392 - acc: 0.9989\n",
      "Epoch 50/100\n",
      "898/898 [==============================] - 0s 106us/step - loss: 0.1630 - categorical_crossentropy: 0.0391 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.1609 - categorical_crossentropy: 0.0384 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "898/898 [==============================] - 0s 89us/step - loss: 0.1589 - categorical_crossentropy: 0.0377 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "898/898 [==============================] - 0s 99us/step - loss: 0.1573 - categorical_crossentropy: 0.0374 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "898/898 [==============================] - 0s 76us/step - loss: 0.1559 - categorical_crossentropy: 0.0373 - acc: 0.9989\n",
      "Epoch 55/100\n",
      "898/898 [==============================] - 0s 54us/step - loss: 0.1545 - categorical_crossentropy: 0.0371 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "898/898 [==============================] - 0s 83us/step - loss: 0.1530 - categorical_crossentropy: 0.0367 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "898/898 [==============================] - 0s 96us/step - loss: 0.1515 - categorical_crossentropy: 0.0363 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "898/898 [==============================] - 0s 78us/step - loss: 0.1504 - categorical_crossentropy: 0.0364 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "898/898 [==============================] - 0s 89us/step - loss: 0.1492 - categorical_crossentropy: 0.0361 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "898/898 [==============================] - 0s 65us/step - loss: 0.1480 - categorical_crossentropy: 0.0359 - acc: 0.9989\n",
      "Epoch 61/100\n",
      "898/898 [==============================] - 0s 96us/step - loss: 0.1527 - categorical_crossentropy: 0.0410 - acc: 0.9978\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 0s 85us/step - loss: 0.1476 - categorical_crossentropy: 0.0362 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "898/898 [==============================] - 0s 88us/step - loss: 0.1458 - categorical_crossentropy: 0.0352 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "898/898 [==============================] - 0s 92us/step - loss: 0.1443 - categorical_crossentropy: 0.0347 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "898/898 [==============================] - 0s 93us/step - loss: 0.1439 - categorical_crossentropy: 0.0349 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "898/898 [==============================] - 0s 102us/step - loss: 0.1425 - categorical_crossentropy: 0.0342 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "898/898 [==============================] - 0s 66us/step - loss: 0.1413 - categorical_crossentropy: 0.0336 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "898/898 [==============================] - 0s 66us/step - loss: 0.1403 - categorical_crossentropy: 0.0333 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "898/898 [==============================] - 0s 91us/step - loss: 0.1393 - categorical_crossentropy: 0.0328 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "898/898 [==============================] - 0s 78us/step - loss: 0.1387 - categorical_crossentropy: 0.0329 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "898/898 [==============================] - 0s 69us/step - loss: 0.1378 - categorical_crossentropy: 0.0327 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "898/898 [==============================] - 0s 79us/step - loss: 0.1373 - categorical_crossentropy: 0.0327 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "898/898 [==============================] - 0s 83us/step - loss: 0.1365 - categorical_crossentropy: 0.0326 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "898/898 [==============================] - 0s 74us/step - loss: 0.1356 - categorical_crossentropy: 0.0323 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "898/898 [==============================] - 0s 71us/step - loss: 0.1355 - categorical_crossentropy: 0.0326 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "898/898 [==============================] - 0s 97us/step - loss: 0.1349 - categorical_crossentropy: 0.0322 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "898/898 [==============================] - 0s 70us/step - loss: 0.1339 - categorical_crossentropy: 0.0317 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "898/898 [==============================] - 0s 71us/step - loss: 0.1334 - categorical_crossentropy: 0.0317 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "898/898 [==============================] - 0s 94us/step - loss: 0.1330 - categorical_crossentropy: 0.0318 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "898/898 [==============================] - 0s 79us/step - loss: 0.1328 - categorical_crossentropy: 0.0319 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "898/898 [==============================] - 0s 72us/step - loss: 0.1323 - categorical_crossentropy: 0.0315 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "898/898 [==============================] - ETA: 0s - loss: 0.1214 - categorical_crossentropy: 0.0208 - acc: 1.00 - 0s 60us/step - loss: 0.1316 - categorical_crossentropy: 0.0313 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "898/898 [==============================] - 0s 107us/step - loss: 0.1312 - categorical_crossentropy: 0.0313 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "898/898 [==============================] - 0s 86us/step - loss: 0.1309 - categorical_crossentropy: 0.0313 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "898/898 [==============================] - 0s 83us/step - loss: 0.1301 - categorical_crossentropy: 0.0307 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "898/898 [==============================] - 0s 78us/step - loss: 0.1297 - categorical_crossentropy: 0.0307 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "898/898 [==============================] - 0s 77us/step - loss: 0.1293 - categorical_crossentropy: 0.0307 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "898/898 [==============================] - 0s 99us/step - loss: 0.1287 - categorical_crossentropy: 0.0304 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "898/898 [==============================] - 0s 102us/step - loss: 0.1287 - categorical_crossentropy: 0.0305 - acc: 0.9989\n",
      "Epoch 90/100\n",
      "898/898 [==============================] - 0s 71us/step - loss: 0.1316 - categorical_crossentropy: 0.0333 - acc: 0.9989\n",
      "Epoch 91/100\n",
      "898/898 [==============================] - 0s 83us/step - loss: 0.1292 - categorical_crossentropy: 0.0310 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "898/898 [==============================] - 0s 127us/step - loss: 0.1277 - categorical_crossentropy: 0.0299 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "898/898 [==============================] - 0s 119us/step - loss: 0.1272 - categorical_crossentropy: 0.0298 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "898/898 [==============================] - 0s 77us/step - loss: 0.1266 - categorical_crossentropy: 0.0296 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "898/898 [==============================] - 0s 109us/step - loss: 0.1265 - categorical_crossentropy: 0.0296 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "898/898 [==============================] - 0s 98us/step - loss: 0.1263 - categorical_crossentropy: 0.0297 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "898/898 [==============================] - 0s 100us/step - loss: 0.1262 - categorical_crossentropy: 0.0297 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "898/898 [==============================] - 0s 73us/step - loss: 0.1256 - categorical_crossentropy: 0.0293 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "898/898 [==============================] - 0s 100us/step - loss: 0.1254 - categorical_crossentropy: 0.0293 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "898/898 [==============================] - 0s 76us/step - loss: 0.1251 - categorical_crossentropy: 0.0291 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe617f64198>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_digits_train,to_categorical(y_digits_train),epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 0s 184us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1234674906080178, 0.02756423144424977, 1.0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_train,to_categorical(y_digits_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18962749268640003, 0.09372423284244749, 0.9744160177975528]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_test,to_categorical(y_digits_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# druga współrzędna to czysty logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Grafika/dropout.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout to specjalna warstwa, która podczas treningu 'wyłącza' losowe neurony z pewnym prawdopodobieństwem $p$ (w każdym batchu wyłączone są inne). Dzięki temu każdy neuron musi 'nauczyć' się radzić sobie z mniejszą ilością danych.  \n",
    "\n",
    "Następnie podczas predykcji, wszystkie neurony są włączane, a ich wyjścia są skalowane przez ustalone wcześniej prawdopodobieństwo $p$ - tak, aby suma sygnałów wpadających do neuronów była wciąż tego samego rzędu.  \n",
    "\n",
    "Możemy tą operację intuicyjnie tłumaczyć jako ensembling robiony \"w locie\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60,input_dim=X_digits_train.shape[1],activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 2.4253 - acc: 0.1971\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.8195 - acc: 0.3820\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.3626 - acc: 0.5668\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.0953 - acc: 0.6815\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.9704 - acc: 0.7249\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.8340 - acc: 0.7595\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.7577 - acc: 0.7817\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.6640 - acc: 0.8107\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.5731 - acc: 0.8374\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.5525 - acc: 0.8363\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.4917 - acc: 0.8608\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.4937 - acc: 0.8686\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.4154 - acc: 0.8820\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.4046 - acc: 0.8864\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.3714 - acc: 0.8964\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.3570 - acc: 0.9076\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.3113 - acc: 0.9176\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.3063 - acc: 0.9209\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.3262 - acc: 0.8976\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.3081 - acc: 0.9076\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.2763 - acc: 0.9220\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.2483 - acc: 0.9432\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.2596 - acc: 0.9187\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.2583 - acc: 0.9176\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.2272 - acc: 0.9321\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.2412 - acc: 0.9354\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.2359 - acc: 0.9232\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.2356 - acc: 0.9410\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.1980 - acc: 0.9477\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.1959 - acc: 0.9443\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.1984 - acc: 0.9443\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.1728 - acc: 0.9543\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.1703 - acc: 0.9577\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.1665 - acc: 0.9499\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.1695 - acc: 0.9488\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.1807 - acc: 0.9454\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.1725 - acc: 0.9499\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.1713 - acc: 0.9488\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.1718 - acc: 0.9521\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.1423 - acc: 0.9610\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.1703 - acc: 0.9465\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.1539 - acc: 0.9621\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.1471 - acc: 0.9610\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.1436 - acc: 0.9577\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.1442 - acc: 0.9532\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.1410 - acc: 0.9532\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.1339 - acc: 0.9633\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.1450 - acc: 0.9588\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.1309 - acc: 0.9621\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.1560 - acc: 0.9577\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.1369 - acc: 0.9588\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.1109 - acc: 0.9655\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.1370 - acc: 0.9521\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.1096 - acc: 0.9733\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.1068 - acc: 0.9710\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.1200 - acc: 0.9655\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.1115 - acc: 0.9699\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.1185 - acc: 0.9666\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.1208 - acc: 0.9610\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.1133 - acc: 0.9655\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0993 - acc: 0.9722\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.1009 - acc: 0.9755\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0902 - acc: 0.9811\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0902 - acc: 0.9800\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.1183 - acc: 0.9621\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.1022 - acc: 0.9733\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0989 - acc: 0.9755\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0953 - acc: 0.9710\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.1032 - acc: 0.9677\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0906 - acc: 0.9710\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.1079 - acc: 0.9699\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0862 - acc: 0.9688\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0796 - acc: 0.9788\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0878 - acc: 0.9777\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0942 - acc: 0.9688\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0908 - acc: 0.9822\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0844 - acc: 0.9722\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0806 - acc: 0.9777\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0873 - acc: 0.9755\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0972 - acc: 0.9710\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0803 - acc: 0.9777\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0724 - acc: 0.9811\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0748 - acc: 0.9788\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0896 - acc: 0.9699\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0832 - acc: 0.9811\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0773 - acc: 0.9733\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0658 - acc: 0.9855\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0782 - acc: 0.9755\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0709 - acc: 0.9766\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0776 - acc: 0.9788\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0717 - acc: 0.9788\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0597 - acc: 0.9855\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0626 - acc: 0.9844\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0733 - acc: 0.9788\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0671 - acc: 0.9833\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0651 - acc: 0.9833\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0692 - acc: 0.9800\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0621 - acc: 0.9811\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0892 - acc: 0.9699\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0663 - acc: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe617f73860>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_digits_train,to_categorical(y_digits_train),epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - 0s 291us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008388164692974747, 0.9988864142538976]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_train,to_categorical(y_digits_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899/899 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10735063254729627, 0.9755283648498332]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_digits_test,to_categorical(y_digits_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy tutaj efekt podobny do ensemblingu - na każdej z epok accuracy nie jest aż tak wysokie, ale ogólny wynik na zbiorze testowym jest już w porządku."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
