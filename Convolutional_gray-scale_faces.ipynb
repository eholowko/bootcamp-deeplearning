{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wielowarstwowa sieć konwolucyjna\n",
    "\n",
    "Wielowarstwowe sieci konwolucyjne wykorzystują wielokrotne składanie operacji filtrowania i uczą się wykrywać bardzo złożone zależności.\n",
    "\n",
    "Wówczas każda kolejna warstwa w jakiś sposób agreguje informacje z poprzedniej warstwy do ogólniejszego poziomu. Przykladowa interpretacja w kontekście klasyfikacji czy na danym zdjęciu jest człowiek:\n",
    "- pierwsza warstwa: rozpoznawianie kształtów/konturów\n",
    "- druga warstwa: detekcja części ciała\n",
    "- trzecia: detekcja człowiek\n",
    "\n",
    "\n",
    "<img src=\"https://adeshpande3.github.io/assets/LeNet.png\" width=\"700\">\n",
    "Źródło: https://adeshpande3.github.io/assets/LeNet.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sieć konwolucyjna uczy się ekstrachować istotne \"informacje\" - parametrami sieci są wagi w filtrach.\n",
    "\n",
    "Czyli sieć sama uczy się tego, co jest istotne w danych dla naszego celu.\n",
    "\n",
    "W sieciach konwolucyjnych na wyjście splotu nakłada się funkcję aktywacji. Z reguły jest to ReLU:\n",
    "\n",
    "<img src=\"https://ml4a.github.io/images/figures/relu.png\" width=\"350\">\n",
    "\n",
    "Źródło: https://ml4a.github.io/images/figures/relu.png\n",
    "\n",
    "Takie przekształcenie można interpretować w następujący sposób: jeżeli w danym obszarze jest coś co dany filtr \"rozpoznaje\" (wartość splotu większa od 0), to zwracamy po prostu wynik splotu. Natomiast jeśli dane nie pasują do danego filtra (wartość ujemna), to niezaleznie od tego co w tych danych jest, zwracamy 0, które mówi, że nie ma tego czego szukamy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyjście sieci\n",
    "\n",
    "Ostatnia warsta konwolucyjna (lub pooling) jest rozwijana do wektora. Ten wektor jest przepuszczany przez warstwy dense, które prowadzą do predykcji. Oczywiście można dokonywać predykcji bezpośrednio z rozwiniętego wektora.\n",
    "\n",
    "#### Uwaga (przypomnienie). Filtr dla obrazka 2D jest tablicą 2D. Natomiast kolejne warstwy są 3D - dochodzi wymiar liczby filtrów. Dlatego dalsze filtry są kostami 3D, które mają głębokość równą liczbie filtrów w poprzedniej warstwie.\n",
    "\n",
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/_jcr_content/mainParsys/image_copy.img.jpg/1497876372993.jpg\" width=\"700\">\n",
    "\n",
    "Źródło: https://www.mathworks.com/content/mathworks/www/en/discovery/convolutional-neural-network/_jcr_content/mainParsys/image_copy.img.jpg/1497876372993.jpg\n",
    "\n",
    "Naturalnie, jeżeli na wejściu mamy obiekt więcej niż dwu-wymiarowy to już pierwsza warstwa używa filtrów, które są kostkami.\n",
    "\n",
    "## Strides - wielkość kroku przesunięcia\n",
    "\n",
    "Określa dokładność z jaką chcemy skanować dane.\n",
    "\n",
    "Strides = (1,1)\n",
    "\n",
    "<img src=\"https://adeshpande3.github.io/assets/Stride1.png\" width=\"600\">\n",
    "\n",
    "Strides = (2,2)\n",
    "\n",
    "<img src=\"https://adeshpande3.github.io/assets/Stride2.png\" width=\"600\">\n",
    "\n",
    "Źródło: https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeszcze jednym istotnym parametrem jest rozmiar filtra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gray-scale faces\n",
    "\n",
    "http://scikit-learn.org/0.15/auto_examples/applications/face_recognition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D,AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people = fetch_lfw_people(min_faces_per_person=70,resize=0.4)\n",
    "\n",
    "X = lfw_people.images\n",
    "y = lfw_people.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "       'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((1288,50,37,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 50, 37)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfw_people.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 50, 37, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(516, 50, 37, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1,:,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMYAAAD8CAYAAAAsetuWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDGMENgxjBDYMYwQ2DGMENgxjBP8P3cxHAA0BbZkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1,:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772, 50, 37, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(50,37,1)))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=3)#jeśli przez 3 kolejne kroki model sie nie poprawi to przerywa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 1850)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 12957     \n",
      "=================================================================\n",
      "Total params: 12,957\n",
      "Trainable params: 12,957\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      " - 0s - loss: 1.9030 - acc: 0.2971 - val_loss: 1.7442 - val_acc: 0.4041\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.7158 - acc: 0.4041 - val_loss: 1.6842 - val_acc: 0.4249\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6338 - acc: 0.4093 - val_loss: 1.6144 - val_acc: 0.4093\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.5974 - acc: 0.4231 - val_loss: 1.6289 - val_acc: 0.4611\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.5412 - acc: 0.4663 - val_loss: 1.5195 - val_acc: 0.4819\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.4701 - acc: 0.4784 - val_loss: 1.6021 - val_acc: 0.4301\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.4776 - acc: 0.4456 - val_loss: 1.4485 - val_acc: 0.5751\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.3920 - acc: 0.5285 - val_loss: 1.3779 - val_acc: 0.5078\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.3549 - acc: 0.5216 - val_loss: 1.4356 - val_acc: 0.4974\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.3321 - acc: 0.5164 - val_loss: 1.3307 - val_acc: 0.5959\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.2776 - acc: 0.5613 - val_loss: 1.2851 - val_acc: 0.5337\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.2325 - acc: 0.5579 - val_loss: 1.3512 - val_acc: 0.5544\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.2269 - acc: 0.5751 - val_loss: 1.2622 - val_acc: 0.6580\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.2370 - acc: 0.5717 - val_loss: 1.2748 - val_acc: 0.4870\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.2090 - acc: 0.5838 - val_loss: 1.3412 - val_acc: 0.5855\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.1706 - acc: 0.5838 - val_loss: 1.1973 - val_acc: 0.5699\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.1107 - acc: 0.6321 - val_loss: 1.1978 - val_acc: 0.6269\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.0809 - acc: 0.6425 - val_loss: 1.2780 - val_acc: 0.6062\n",
      "Epoch 19/100\n",
      " - 0s - loss: 1.0781 - acc: 0.6321 - val_loss: 1.1867 - val_acc: 0.5959\n",
      "Epoch 20/100\n",
      " - 0s - loss: 1.0617 - acc: 0.6304 - val_loss: 1.1637 - val_acc: 0.5907\n",
      "Epoch 21/100\n",
      " - 0s - loss: 1.0021 - acc: 0.6822 - val_loss: 1.1633 - val_acc: 0.5699\n",
      "Epoch 22/100\n",
      " - 0s - loss: 1.0840 - acc: 0.5993 - val_loss: 1.1841 - val_acc: 0.5699\n",
      "Epoch 23/100\n",
      " - 0s - loss: 1.0237 - acc: 0.6442 - val_loss: 1.1297 - val_acc: 0.6580\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.0075 - acc: 0.6494 - val_loss: 1.1174 - val_acc: 0.5959\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.9786 - acc: 0.6684 - val_loss: 1.1015 - val_acc: 0.6373\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.9874 - acc: 0.6598 - val_loss: 1.0811 - val_acc: 0.6166\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.9070 - acc: 0.7375 - val_loss: 1.0814 - val_acc: 0.6062\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.8983 - acc: 0.7323 - val_loss: 1.0313 - val_acc: 0.6218\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.8956 - acc: 0.7168 - val_loss: 0.9989 - val_acc: 0.6632\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.8974 - acc: 0.7116 - val_loss: 0.9852 - val_acc: 0.6528\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.8818 - acc: 0.7375 - val_loss: 1.0418 - val_acc: 0.5959\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.9251 - acc: 0.6770 - val_loss: 0.9954 - val_acc: 0.6373\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.8597 - acc: 0.7098 - val_loss: 0.9859 - val_acc: 0.6528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa8970ef0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.25,epochs=100,callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/772 [==============================] - 0s 56us/step\n",
      "[0.933119172259316, 0.6787564766839378]\n",
      "516/516 [==============================] - 0s 45us/step\n",
      "[1.025804177735203, 0.6531007751937985]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train,y_train))\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with one dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 1850)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               185100    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 185,807\n",
      "Trainable params: 185,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(50,37,1)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=3)#jeśli przez 3 kolejne kroi model sie nie poprawi to przerywa\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.8935 - acc: 0.3817 - val_loss: 1.6644 - val_acc: 0.4041\n",
      "Epoch 2/100\n",
      " - 0s - loss: 1.6899 - acc: 0.4145 - val_loss: 1.7608 - val_acc: 0.4041\n",
      "Epoch 3/100\n",
      " - 0s - loss: 1.6569 - acc: 0.4162 - val_loss: 1.5992 - val_acc: 0.4819\n",
      "Epoch 4/100\n",
      " - 0s - loss: 1.5218 - acc: 0.4715 - val_loss: 1.5464 - val_acc: 0.4093\n",
      "Epoch 5/100\n",
      " - 0s - loss: 1.4956 - acc: 0.4836 - val_loss: 1.4888 - val_acc: 0.4611\n",
      "Epoch 6/100\n",
      " - 0s - loss: 1.3857 - acc: 0.5060 - val_loss: 1.3927 - val_acc: 0.5751\n",
      "Epoch 7/100\n",
      " - 0s - loss: 1.4428 - acc: 0.5043 - val_loss: 1.5193 - val_acc: 0.5130\n",
      "Epoch 8/100\n",
      " - 0s - loss: 1.3154 - acc: 0.4991 - val_loss: 1.3649 - val_acc: 0.5544\n",
      "Epoch 9/100\n",
      " - 0s - loss: 1.2446 - acc: 0.5596 - val_loss: 1.2964 - val_acc: 0.5855\n",
      "Epoch 10/100\n",
      " - 0s - loss: 1.2128 - acc: 0.5717 - val_loss: 1.2801 - val_acc: 0.5751\n",
      "Epoch 11/100\n",
      " - 0s - loss: 1.1618 - acc: 0.5889 - val_loss: 1.1779 - val_acc: 0.6010\n",
      "Epoch 12/100\n",
      " - 0s - loss: 1.1340 - acc: 0.6131 - val_loss: 1.2153 - val_acc: 0.6010\n",
      "Epoch 13/100\n",
      " - 0s - loss: 1.0965 - acc: 0.6235 - val_loss: 1.2679 - val_acc: 0.5337\n",
      "Epoch 14/100\n",
      " - 0s - loss: 1.0914 - acc: 0.6339 - val_loss: 1.1566 - val_acc: 0.5699\n",
      "Epoch 15/100\n",
      " - 0s - loss: 1.0521 - acc: 0.6408 - val_loss: 1.1774 - val_acc: 0.5389\n",
      "Epoch 16/100\n",
      " - 0s - loss: 1.0812 - acc: 0.6166 - val_loss: 1.1285 - val_acc: 0.6114\n",
      "Epoch 17/100\n",
      " - 0s - loss: 1.0230 - acc: 0.6615 - val_loss: 1.0732 - val_acc: 0.5803\n",
      "Epoch 18/100\n",
      " - 0s - loss: 1.0085 - acc: 0.6718 - val_loss: 1.1624 - val_acc: 0.5596\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.9484 - acc: 0.6857 - val_loss: 1.1941 - val_acc: 0.6062\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.9548 - acc: 0.6649 - val_loss: 1.0105 - val_acc: 0.6632\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.8738 - acc: 0.7081 - val_loss: 0.9502 - val_acc: 0.7098\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.8395 - acc: 0.7323 - val_loss: 0.9288 - val_acc: 0.7150\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.8596 - acc: 0.7306 - val_loss: 1.3178 - val_acc: 0.5181\n",
      "Epoch 24/100\n",
      " - 0s - loss: 1.0781 - acc: 0.6131 - val_loss: 1.1112 - val_acc: 0.6632\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.8808 - acc: 0.6805 - val_loss: 1.0155 - val_acc: 0.6788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa5382f28>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.25,epochs=100,callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/772 [==============================] - 0s 72us/step\n",
      "[0.9040276531728438, 0.7150259067357513]\n",
      "516/516 [==============================] - 0s 49us/step\n",
      "[1.0642260516336721, 0.6434108527131783]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train,y_train))\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with one convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 35, 8)         80        \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 13440)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               1344100   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 1,344,887\n",
      "Trainable params: 1,344,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv = Sequential()\n",
    "\n",
    "model_conv.add(Conv2D(8,(3,3),activation='relu',input_shape=(50,37,1)))\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(100,activation='relu'))\n",
    "model_conv.add(Dense(7,activation='softmax'))\n",
    "model_conv.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=3)#jeśli przez 3 kolejne kroi model sie nie poprawi to przerywa\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 1.7573 - acc: 0.3454 - val_loss: 1.6043 - val_acc: 0.4041\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.5734 - acc: 0.4301 - val_loss: 1.5797 - val_acc: 0.4767\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.4319 - acc: 0.4732 - val_loss: 1.4691 - val_acc: 0.4767\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.3124 - acc: 0.5112 - val_loss: 1.2914 - val_acc: 0.5544\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.1503 - acc: 0.6097 - val_loss: 1.2133 - val_acc: 0.6114\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.0430 - acc: 0.6667 - val_loss: 1.1365 - val_acc: 0.6373\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.9116 - acc: 0.7340 - val_loss: 1.1096 - val_acc: 0.5907\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.8099 - acc: 0.7686 - val_loss: 1.0252 - val_acc: 0.6580\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.7262 - acc: 0.7703 - val_loss: 0.9078 - val_acc: 0.7047\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.6617 - acc: 0.8290 - val_loss: 0.9903 - val_acc: 0.6269\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.6040 - acc: 0.8135 - val_loss: 0.9609 - val_acc: 0.6528\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.4979 - acc: 0.8670 - val_loss: 0.7621 - val_acc: 0.7668\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.4325 - acc: 0.8929 - val_loss: 0.7556 - val_acc: 0.7409\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.3820 - acc: 0.9154 - val_loss: 0.6661 - val_acc: 0.7876\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.3719 - acc: 0.9136 - val_loss: 0.6673 - val_acc: 0.7979\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.2948 - acc: 0.9430 - val_loss: 0.6344 - val_acc: 0.7927\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.2653 - acc: 0.9534 - val_loss: 0.5702 - val_acc: 0.8238\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.2378 - acc: 0.9620 - val_loss: 0.5528 - val_acc: 0.8187\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.2687 - acc: 0.9361 - val_loss: 0.5445 - val_acc: 0.8342\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.1943 - acc: 0.9741 - val_loss: 0.5646 - val_acc: 0.8187\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.1575 - acc: 0.9810 - val_loss: 0.6595 - val_acc: 0.7668\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.1911 - acc: 0.9603 - val_loss: 0.5508 - val_acc: 0.8187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa5bfa208>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fit(X_train,y_train,validation_split=0.25,epochs=100,callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/772 [==============================] - 1s 655us/step\n",
      "[0.23386973188948754, 0.9507772020725389]\n",
      "516/516 [==============================] - 0s 664us/step\n",
      "[0.6116619253343389, 0.8042635658914729]\n"
     ]
    }
   ],
   "source": [
    "print(model_conv.evaluate(X_train,y_train))\n",
    "print(model_conv.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 50, 37, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 18, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               460928    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 461,911\n",
      "Trainable params: 461,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Conv2D(8,(3,3),activation='relu',input_shape=(50,37,1),padding='same'))\n",
    "model_conv.add(MaxPooling2D())\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(128,activation='relu'))\n",
    "model_conv.add(Dense(7,activation='softmax'))\n",
    "model_conv.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=3)#jeśli przez 3 kolejne kroi model sie nie poprawi to przerywa\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 0.2157 - acc: 0.9620 - val_loss: 0.5921 - val_acc: 0.7513\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.1753 - acc: 0.9741 - val_loss: 0.4797 - val_acc: 0.8446\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.1495 - acc: 0.9931 - val_loss: 0.5429 - val_acc: 0.8238\n",
      "Epoch 4/100\n",
      " - 1s - loss: 0.1440 - acc: 0.9914 - val_loss: 0.5215 - val_acc: 0.8187\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.1473 - acc: 0.9775 - val_loss: 0.4674 - val_acc: 0.8601\n",
      "Epoch 6/100\n",
      " - 1s - loss: 0.1073 - acc: 0.9896 - val_loss: 0.4345 - val_acc: 0.8497\n",
      "Epoch 7/100\n",
      " - 1s - loss: 0.1101 - acc: 0.9862 - val_loss: 0.4518 - val_acc: 0.8446\n",
      "Epoch 8/100\n",
      " - 1s - loss: 0.0826 - acc: 1.0000 - val_loss: 0.4209 - val_acc: 0.8653\n",
      "Epoch 9/100\n",
      " - 1s - loss: 0.0894 - acc: 0.9879 - val_loss: 0.4843 - val_acc: 0.8238\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.0833 - acc: 0.9983 - val_loss: 0.4770 - val_acc: 0.8083\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.0651 - acc: 1.0000 - val_loss: 0.4513 - val_acc: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa5397a90>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fit(X_train,y_train,validation_split=0.25,epochs=100,callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/772 [==============================] - 1s 648us/step\n",
      "[0.15541127327964713, 0.9585492227979274]\n",
      "516/516 [==============================] - 0s 556us/step\n",
      "[0.5385752914025802, 0.8468992248062015]\n"
     ]
    }
   ],
   "source": [
    "print(model_conv.evaluate(X_train,y_train))\n",
    "print(model_conv.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 50, 37, 8)         80        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 25, 18, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               360100    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 360,887\n",
      "Trainable params: 360,887\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_conv = Sequential()\n",
    "model_conv.add(Conv2D(8,(3,3),activation='relu',input_shape=(50,37,1),padding='same'))\n",
    "model_conv.add(AveragePooling2D())\n",
    "model_conv.add(Flatten())\n",
    "model_conv.add(Dense(100,activation='relu'))\n",
    "model_conv.add(Dense(7,activation='softmax'))\n",
    "model_conv.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(patience=3)#jeśli przez 3 kolejne kroi model sie nie poprawi to przerywa\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 579 samples, validate on 193 samples\n",
      "Epoch 1/100\n",
      " - 1s - loss: 1.7613 - acc: 0.3748 - val_loss: 1.6809 - val_acc: 0.4041\n",
      "Epoch 2/100\n",
      " - 1s - loss: 1.6838 - acc: 0.3955 - val_loss: 1.6327 - val_acc: 0.4041\n",
      "Epoch 3/100\n",
      " - 1s - loss: 1.6249 - acc: 0.3955 - val_loss: 1.5870 - val_acc: 0.4093\n",
      "Epoch 4/100\n",
      " - 1s - loss: 1.5183 - acc: 0.4335 - val_loss: 1.5377 - val_acc: 0.4249\n",
      "Epoch 5/100\n",
      " - 1s - loss: 1.4370 - acc: 0.4870 - val_loss: 1.4455 - val_acc: 0.4560\n",
      "Epoch 6/100\n",
      " - 1s - loss: 1.3636 - acc: 0.4819 - val_loss: 1.4326 - val_acc: 0.5803\n",
      "Epoch 7/100\n",
      " - 1s - loss: 1.2710 - acc: 0.5544 - val_loss: 1.3319 - val_acc: 0.5648\n",
      "Epoch 8/100\n",
      " - 1s - loss: 1.1663 - acc: 0.5734 - val_loss: 1.1886 - val_acc: 0.5907\n",
      "Epoch 9/100\n",
      " - 1s - loss: 1.0972 - acc: 0.6442 - val_loss: 1.1721 - val_acc: 0.5803\n",
      "Epoch 10/100\n",
      " - 1s - loss: 0.9755 - acc: 0.6667 - val_loss: 1.1141 - val_acc: 0.6321\n",
      "Epoch 11/100\n",
      " - 1s - loss: 0.8904 - acc: 0.7098 - val_loss: 1.0004 - val_acc: 0.6528\n",
      "Epoch 12/100\n",
      " - 1s - loss: 0.8298 - acc: 0.7116 - val_loss: 1.0493 - val_acc: 0.6218\n",
      "Epoch 13/100\n",
      " - 1s - loss: 0.8003 - acc: 0.7098 - val_loss: 0.9019 - val_acc: 0.6684\n",
      "Epoch 14/100\n",
      " - 1s - loss: 0.6987 - acc: 0.7824 - val_loss: 0.9096 - val_acc: 0.6321\n",
      "Epoch 15/100\n",
      " - 1s - loss: 0.6390 - acc: 0.8152 - val_loss: 0.7899 - val_acc: 0.7306\n",
      "Epoch 16/100\n",
      " - 1s - loss: 0.5834 - acc: 0.8463 - val_loss: 0.7838 - val_acc: 0.7565\n",
      "Epoch 17/100\n",
      " - 1s - loss: 0.5721 - acc: 0.8325 - val_loss: 0.7917 - val_acc: 0.7254\n",
      "Epoch 18/100\n",
      " - 1s - loss: 0.4755 - acc: 0.8895 - val_loss: 0.7020 - val_acc: 0.7720\n",
      "Epoch 19/100\n",
      " - 1s - loss: 0.4577 - acc: 0.8791 - val_loss: 0.6885 - val_acc: 0.7565\n",
      "Epoch 20/100\n",
      " - 1s - loss: 0.4290 - acc: 0.8929 - val_loss: 0.6659 - val_acc: 0.7979\n",
      "Epoch 21/100\n",
      " - 1s - loss: 0.3965 - acc: 0.8895 - val_loss: 0.6766 - val_acc: 0.7461\n",
      "Epoch 22/100\n",
      " - 1s - loss: 0.4028 - acc: 0.8964 - val_loss: 0.6518 - val_acc: 0.7617\n",
      "Epoch 23/100\n",
      " - 1s - loss: 0.3967 - acc: 0.8946 - val_loss: 0.7919 - val_acc: 0.7306\n",
      "Epoch 24/100\n",
      " - 1s - loss: 0.3854 - acc: 0.8912 - val_loss: 0.6151 - val_acc: 0.8083\n",
      "Epoch 25/100\n",
      " - 1s - loss: 0.3393 - acc: 0.9154 - val_loss: 0.6734 - val_acc: 0.7927\n",
      "Epoch 26/100\n",
      " - 1s - loss: 0.3120 - acc: 0.9275 - val_loss: 0.6212 - val_acc: 0.7720\n",
      "Epoch 27/100\n",
      " - 1s - loss: 0.2784 - acc: 0.9344 - val_loss: 0.6234 - val_acc: 0.8083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef9c0250b8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.fit(X_train,y_train,validation_split=0.25,epochs=100,callbacks=[early_stopping],verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772/772 [==============================] - 1s 721us/step\n",
      "[0.3716142345895421, 0.9106217616580311]\n",
      "516/516 [==============================] - 0s 695us/step\n",
      "[0.6675881325274475, 0.7868217054263565]\n"
     ]
    }
   ],
   "source": [
    "print(model_conv.evaluate(X_train,y_train))\n",
    "print(model_conv.evaluate(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
